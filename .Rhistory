data(Wage)
dim(Wage)
str(Wage)
summary(Wage)
mean(Wage$year)
summary(wage$year)
summary(Wage$year)
median(Wage$year)
str(Wage)
summary(Wage)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=F)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
mean(training$capitalAve)
sd(training$capitalAve)
sd(testing$capitalAve)
mean(testing$capitalAve)
training[1,]
training[,-58]
x<- preProcess(training[,-58], method=c("center", "scale"))
x
x
class(x)
dim(x)
predict(x, training[,-58])
predict(x, training)
training
dim(training)
dim(training)[1]
rbinom(3451, size=1, prob=0.05)
rbinom(3451, size=1, prob=0.05)==1
count(rbinom(3451, size=1, prob=0.05))
length(rbinom(3451, size=1, prob=0.05))
sum(rbinom(3451, size=1, prob=0.05))
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
AlzheimerDisease
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
AlzheimerDisease
data(a)
data(AlzheimerDisease)
data.frame(predictors)
predictors
dim(predictors)
str(predictors)
dim(diagnosis)
diagnosis
AlzheimerDisease
adData = data.frame(diagnosis,predictors)
str(adData)
length(diagnosis)
dim(predictors)
dim(adData)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
dim(training)
dim(testing)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
dim(testing)
dim(training)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
dim(testing)
dim(testing)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
inTrain
length(inTrain)
dim(concrete)
dim(concrete)[1]*3/4
head(concrete)
str(concrete)
summary(cement)
summary(concrete)
plot(cement ~ CompresiveStrength, concrete)
plot(Cement ~ CompresiveStrength, concrete)
plot(Cement ~ CompressiveStrength, concrete)
install.packages("Hmisc")
library(Hmisc)
names(concrete)
range(concrete$Age)
quantile(concrete$Age)
mean(concrete$Age)
plot(CompressiveStrength ~ Cement, concrete)
cutAge <- cut2(concrete$age, g=3)
str(concrete$Age)
cutAge <- cut2(concrete$Age, g=3)
cutAge
table(cutAge)
cutAge <- cut2(concrete$Age, g=1)
table(cutAge)
cutAge <- cut2(concrete$Age, g=2)
table(cutAge)
cutAge <- cut2(concrete$Age, g=3)
table(cutAge)
cutAge <- cut2(concrete$Age, g=4)
table(cutAge)
mode(concrete$Age)
median(concrete$Age)
mod(concrete$Age)
mode(concrete$Age)
plot(CompressiveStrength ~ Cement, concrete, fill=cutAge)
qplot(CompressiveStrength, Cement, concrete, fill=cutAge)
qplot(CompressiveStrength, data=Cement, concrete, fill=cutAge)
qplot(CompressiveStrength, data=concrete, concrete, fill=cutAge)
qplot(CompressiveStrength, data=concrete, concrete, fill=cutAge, geom=c("boxplot"))
training
concerte
concrete
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
training
head(training)
mixtures
index <- 1:nrow(training)
index
plot(CompressiveStrength ~ index, training)
index <- seq_along(1:nrow(training))
index1 <- 1:nrow(training)
identical(index, index1)
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[inTrain, ]
testing = mixtures[-inTrain, ]
names <- colnames(concrete)
names <- names[-length(names)]
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
training <- mutate(training, index = 1:nrow(training))
library(dplyr)
training <- mutate(training, index = 1:nrow(training))
training
qplot(index, CompressiveStrength, data = training)
qplot(index, CompressiveStrength, data = training, color=cut2(training$Cement, g=10))
qplot(index, CompressiveStrength, data = training, color=cut2(training$BlastFurnaceSlag, g=10))
qplot(index, CompressiveStrength, data = training, color=cut2(training$BlastFurnaceSlag, g=10))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log(training$Superplasticizer)
)
hist(training$Superplasticizer)
hist(log(training$Superplasticizer+1))
hist(log(training$Superplasticizer))
hist(log(training$Superplasticizer+1))
hist(training$Superplasticizer)
range(training$Superplasticizer)
quantiles(training$Superplasticizer)
quantile(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
index_LI <- grep("[LI")
index_LI <- grep("[LI", training)
index_LI <- grep("[LI]", training)
index_LI
index_LI <- grep("[LI]*", training)
index_LI
index_LI <- grep("[LI].*", training)
index_LI
index_LI <- grep("[Ii][lL].*", training)
index_LI
index_LI <- grep("^[Ii][lL].*", training)
index_LI
index_LI <- grep("^[Ii][lL].*", names(training))
index_LI
length(index_LI)
x<-preProcess(training[,index_LI], method="pca", thresh = 0.9)
x
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
index_LI <- grep("^[Ii][lL].*", names(training))
names(training)
training <- training[,1 + index_LI]
names(training)
training <- training[,1 & index_LI]
names(training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[, c(names(training[index_LI],"diagnosis"))]
training <- training[, c(names(training[index_LI]),"diagnosis"))]
training <- training[, c(names(training[index_LI]),"diagnosis")]
names(training)
testing <- testing[, c(names(testing[index_LI]),"diagnosis")]
names(testing)
names(training)
non_pca_model <- train(diagnosis ~ ., data = training, method="glm")
non_pca_model
predict(non_pca_model, testing)
predict(non_pca_model, testing[-13])
predict(non_pca_model, testing)
x<-predict(non_pca_model, testing)
confusionMatrix(testing[,13], x)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
suppressMessages(library(dplyr))
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
names(new_training)
IL_col_idx <- grep("^[Ii][Ll].*", names(testing))
suppressMessages(library(dplyr))
new_testing <- testing[, c(names(testing)[IL_col_idx], "diagnosis")]
names(new_testing)
# compute the model with non_pca predictors
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
# apply the non pca model on the testing set and check the accuracy
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
# compute the model with pca predictors
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
# apply the PCA model on the testing set
pca_result <- confusionMatrix(new_testing[, 13], predict(pca_model, pc_testing_preds))
pca_result
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
new_training
names(new_training)
head(new_training)
new_training$diagnosis
smallSpam <- spam[,32,34]
prComp <- prcomp(smallSpam)
prComp
prComp$x
prComp$rotation
prComp$center
prComp$x
class(prComp$x)
dim(prComp)
length(prComp)
length(prComp$x)
dim(prComp$x)
plot(prComp$x[,1],prComp$x[,2])
prComp$x[,1]
prComp$x[,2]
smallSpam <- spam[,c(32,34)]
prComp <- prcomp(smallSpam)
prcomp
prComp
prComp$x
prComp$x[,1]
prComp$x[,2]
plot(prComp$x[,1],prComp$x[,2])
prcomp <- prcomp(log10(spam[,-58]+1))
prcpmp$x
prcomp$x
length(prcomp$x)
preProc <- preProcess(log(training[,-58]+1), method="pca", ppcaComp = 2)
preProc <- preProcess(log10(training[,-58]+1), method="pca", ppcaComp = 2)
preProc <- preProcess(log10(training[,-58]+1), method="pca", pcaComp = 2)
training
length(names(training))
preProc <- preProcess(log10(spam[,-58]+1), method="pca", pcaComp = 2)
trainPC <- predict(preProc, log10(spam[,-58]+1))
class(trainPC)
dim(trainPC)
head(train)
head(trainPC)
modelFit <- train(spam$type.~, method = "glm", data = trainPC)
modelFit <- train(spam$type ~. , method = "glm", data=trainPC)
spam$type
modelFit <- train(spam$type ~ ., method ="glm", data=trainPC)
warnings()
data.frame(waiting=80)
inTrain <- createDataPartition(y=faithful$waiting, p=0.5, list = FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col = "blue", xlab="Waiting", ylab="Duration")
lm1 <- lm(eruptions ~ waiting, data= trainFaith)
lm1$fitter
lm1$fitted
predict(lm1)
ord <-  order(faithful$waiting)
ord
ord <-  order(testFaith$waiting)
ord
pred1 <- predict(lm1, newdata=testFaith, interval = "prediction")
pred1
head(pred1)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue")
matlines(testFaith$waiting, pred1, type="l")
matlines(testFaith$waiting, pred1, type="l",col(2,2,1))
matlines(testFaith$waiting, pred1, type="l",col=c(2,2,1))
matlines(testFaith$waiting, pred1, type="l",col=c(1,2,2))
matlines(testFaith$waiting, pred1, type="l",,col=c(1,2,2))
matlines(testFaith$waiting, pred1, type="l",,col=c(1,2,2), lty=c(1,1,1)
)
matlines(testFaith$waiting, pred1, type="l",,col=c(1,2,2), lty=c(1,1,1), lwd = 3)
ord <-  order(testFaith$waiting)
matlines(testFaith$waiting[ord], pred1[ord,], type="l",,col=c(1,2,2), lty=c(1,1,1), lwd = 3)
matlines(testFaith$waiting, pred1, type="l",,col=c(1,2,2), lty=c(1,1,1), lwd = 1)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue")
matlines(testFaith$waiting[ord], pred1[ord,], type="l",,col=c(1,2,2), lty=c(1,1,1), lwd = 3)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue")
matlines(testFaith$waiting, pred1, type="l",,col=c(1,2,2), lty=c(1,1,1), lwd = 3)
data(iris)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=F)
training <- iris(train,)
training <- iris[train,]
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
150*.07
150*.7
150*.3
dim(testing)
qplot(Petal.Width, Sepal.Width, colour=Spercies, data=training)
qplot(Petal.Width, Sepal.Width, colour=Species, data=training)
pairs(iris[,-5])
pairs(iris[,-5], color=species)
pairs(iris, color=species)
pairs(iris)
structure(list(Country = structure(c(5L, 4L, 7L, 2L, 1L, 6L,
3L), .Label = c("Brazil", "Chile", "China", "France", "Germany",
"India", "Netherlands"), class = "factor"), GDP = c(0.46, 0.57,
0.75, 0.56, 0.28, 0.88, 1), Population = c(0.18, 0.09, 0.54,
0.01, 0.02, 0.17, 0.84), Birth.rate = c(87.21, 18.34, 63.91,
14.21, 5.38, 51.19, 209.26), Income = c(43.89, 18.23, 63.91,
12.3, 0.1, 14.61, 160.82), Savings = c(43.32, 0.11, 0, 1.91,
5.29, 36.58, 50.38), Continent = structure(c(2L, 2L, 2L, 3L,
3L, 1L, 1L), .Label = c("Asia", "Europe", "South America"), class = "factor")), .Names = c("Country",
"GDP", "Population", "Birth.rate", "Income", "Savings", "Continent"
), class = "data.frame", row.names = c(NA, -7L))
dt <- structure(list(Country = structure(c(5L, 4L, 7L, 2L, 1L, 6L,
3L), .Label = c("Brazil", "Chile", "China", "France", "Germany",
"India", "Netherlands"), class = "factor"), GDP = c(0.46, 0.57,
0.75, 0.56, 0.28, 0.88, 1), Population = c(0.18, 0.09, 0.54,
0.01, 0.02, 0.17, 0.84), Birth.rate = c(87.21, 18.34, 63.91,
14.21, 5.38, 51.19, 209.26), Income = c(43.89, 18.23, 63.91,
12.3, 0.1, 14.61, 160.82), Savings = c(43.32, 0.11, 0, 1.91,
5.29, 36.58, 50.38), Continent = structure(c(2L, 2L, 2L, 3L,
3L, 1L, 1L), .Label = c("Asia", "Europe", "South America"), class = "factor")), .Names = c("Country",
"GDP", "Population", "Birth.rate", "Income", "Savings", "Continent"
), class = "data.frame", row.names = c(NA, -7L))
dt
for (i in seq(1,length(data),1)) {
plot(data[,i], ylab=names(data[i]), xlab="Country",
text(i, labels=Country, pos=4, cex =.5))
}
for (i in seq(1,length(dt),1)) {
plot(data[,i], ylab=names(dt[i]), xlab="Country",
text(i, labels=Country, pos=4, cex =.5))
}
for (i in seq(1,length(dt),1)) {
plot(dr[,i], ylab=names(dt[i]), xlab="Country",
text(i, labels=Country, pos=4, cex =.5))
}
for (i in seq(1,length(dt),1)) {
plot(dt[,i], ylab=names(dt[i]), xlab="Country",
text(i, labels=Country, pos=4, cex =.5))
}
for (i in seq(1,length(dt),1)) {
plot(dt[,i], ylab=names(dt[i]), xlab="Country",
text(i, labels=dt$Country, pos=4, cex =.5))
}
qplot(Petal.Width, Sepal.Width, colour=Spercies, data=training)
qplot(Petal.Width, Sepal.Width, colour=Species, data=training)
modfit <-  train
modfit <- train(Species~., metho="rpart",data=training)
modfit
modfit$finalModel
x <- predict(modfit, newdata = testing)
x
testing$Species
confusionMatrix(x, testing$Species)
predict(modfit)
confusionMatrix(predict(modfit), testing$Species)
confusionMatrix(predict(modfit), training$Species)
x
getpwd
getpwd()
getwd()
setwd("C:/Users/PC/OneDrive/Personal/Training/Coursera/Data Science Specialization/8. Practical Machine Learning/Week 4 - Course Project")
getwd()
if (!file.exists("pml-training.csv")){
download.file("https://d396qusza40orc.loudfront.net/predmachlearn/pml-training.csv")
}
if (!file.exists("pml-testing.csv")){
download.file("https://d396qusza40orc.loudfront.net/predmachlearn/pml-testing.csv")
}
if (!file.exists("pml-training.csv")){
download.file("https://d396qusza40orc.loudfront.net/predmachlearn/pml-training.csv", "pml-training.csv")
}
if (!file.exists("pml-testing.csv")){
download.file("https://d396qusza40orc.loudfront.net/predmachlearn/pml-testing.csv", "pml-testing.csv")
}
download.file("https://d396qusza40orc.loudfront.net/predmachlearn/pml-training.csv", "pml-training.csv")
if (!file.exists("pml-training.csv")){
download.file("https://d396qusza40orc.loudfront.net/predmachlearn/pml-training.csv", "pml-training.csv")
}
if (!file.exists("pml-testing.csv")){
download.file("https://d396qusza40orc.loudfront.net/predmachlearn/pml-testing.csv", "pml-testing.csv")
}
trainingSet <- read.csv("pml-training.csv"")
testingSet <- read.csv("pml-testing.csv"")
trainingSet <- read.csv("pml-training.csv")
testingSet <- read.csv("pml-testing.csv")
head(trainingSet)
head(testingSet)
dim(trainingSet)
dim(testingSet)
str(trainingSet)
summary(trainingSet)
names(trainingSet)
trainingSet$X
summary(trainingSet$X)
length(trainingSet$X)
summary(trainingSet$user_name)
str(trainingSet$user_name)
setwd("C:/Users/PC/OneDrive/Personal/Training/Coursera/Data Science Specialization/8. Practical Machine Learning/Week 4 - Course Project/Exercise Manner Prediction")
